{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef025619-3187-4414-bedf-d16e25de5f61",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import requests\n",
    "import os\n",
    "from pyspark.sql.functions import regexp_replace, col\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CosmosDBWriteOptimization\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Replace these variables with your Azure Cosmos DB credentials\n",
    "COSMOS_DB_URI = \"\"\n",
    "COSMOS_DB_KEY = \"\"  # Ensure to keep your key secure\n",
    "COSMOS_DB_DATABASE_NAME = \"diskanndb\"\n",
    "COSMOS_DB_CONTAINER_NAME = \"search\"\n",
    "\n",
    "# Azure Blob Storage URL for the JSON file\n",
    "blob_url = \"\"\n",
    "\n",
    "# sample expects file with array of json docs in following format, where embedding is an array of floats that represent the \"abstract\" field:\n",
    "\n",
    "# [\n",
    "#   {\n",
    "#     \"abstract\": \"  $GL_h(n) \\\\\\\\times GL_h(m)$-covariant $h$-bosonic algebras are built by\\\\ncontracting the $GL_q(n) \\\\\\\\times GL_q(m)$-covariant $q$-bosonic algebras\\\\nconsidered by the present author some years ago. Their defining relations are\\\\nwritten in terms of the corresponding $R_h$-matrices. Whenever $n=2$, and $m=1$\\\\nor 2, it is proved by using U_h(sl(2)) Clebsch-Gordan coefficients that they\\\\ncan also be expressed in terms of coupled commutators in a way entirely similar\\\\nto the classical case. Some U_h(sl(2)) rank-1/2 irreducible tensor operators,\\\\nrecently contructed by Aizawa in terms of standard bosonic operators, are shown\\\\nto provide a realization of the $h$-bosonic algebra corresponding to $n=2$ and\\\\n$m=1$.\\\\n\",\n",
    "#     \"authors\": \"C. Quesne\",\n",
    "#     \"authors_parsed\": \"[[\\\"Quesne\\\", \\\"C.\\\", \\\"\\\"]]\",\n",
    "#     \"categories\": \"math.QA hep-th math-ph math.MP\",\n",
    "#     \"comments\": \"7 pages, LaTeX, no figure, presented at the 7th Colloquium ``Quantum\\\\n  Groups and Integrable Systems'', Prague, 18--20 June 1998, submitted to\\\\n  Czech. J. Phys\",\n",
    "#     \"doi\": \"null\",\n",
    "#     \"embedding\": [0.005199998617172241, 0.002000004291534424, 0.0008000133037567139],\n",
    "#     \"id\": \"math_9810161\",\n",
    "#     \"journal-ref\": \"Czech. J. Phys. 48 (1998) 1471-1476\",\n",
    "#     \"license\": \"null\",\n",
    "#     \"report-no\": \"ULB/229/CQ/98/4\",\n",
    "#     \"submitter\": \"Christiane Quesne\",\n",
    "#     \"title\": \"Nonstandard GL_h(n) quantum groups and contraction of covariant\\\\n  q-bosonic algebras\",\n",
    "#     \"update_date\": \"2007-05-23\",\n",
    "#     \"versions\": \"[{\\\"version\\\": \\\"v1\\\", \\\"created\\\": \\\"Wed, 28 Oct 1998 13:50:20 GMT\\\"}]\",\n",
    "#   },\n",
    "#   {\n",
    "#     ... next document\n",
    "#   }\n",
    "# ]\n",
    "\n",
    "# Output file where the JSON file will be stored (mounted path)\n",
    "output_file_path = \"/dbfs/mnt/temp/vectors1-utf8.json\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "\n",
    "# Step 1: Stream the file from the Blob URL and save it to disk\n",
    "response = requests.get(blob_url, stream=True)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "        for chunk in response.iter_content(chunk_size=1024 * 1024, decode_unicode=True):\n",
    "            output_file.write(chunk)\n",
    "    print(f\"File successfully written to {output_file_path}\")\n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
    "\n",
    "# Step 2: Correct the path for Spark to use dbfs:/ format\n",
    "spark_file_path = output_file_path.replace(\"/dbfs\", \"dbfs:\")\n",
    "\n",
    "# Step 3: Read the entire JSON file with schema inference and parallel reads\n",
    "df = spark.read.option(\"multiLine\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .json(spark_file_path)\n",
    "\n",
    "# Step 4: Show the schema to verify the data structure\n",
    "df.printSchema()\n",
    "\n",
    "# Clean the document IDs to remove illegal characters using regex replace\n",
    "df = df.withColumn('id', regexp_replace(col('id'), '[/#\\\\\\\\]', '_'))\n",
    "\n",
    "# Repartition the DataFrame to optimize writes\n",
    "num_partitions = 200  # Adjust this based on your Spark cluster resources\n",
    "df = df.repartition(num_partitions)\n",
    "\n",
    "# Step 5: Write to Cosmos DB in batches and optimize partitions\n",
    "df.write \\\n",
    "    .format(\"cosmos.oltp\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"spark.cosmos.database\", COSMOS_DB_DATABASE_NAME) \\\n",
    "    .option(\"spark.cosmos.container\", COSMOS_DB_CONTAINER_NAME) \\\n",
    "    .option(\"spark.cosmos.accountEndpoint\", COSMOS_DB_URI) \\\n",
    "    .option(\"spark.cosmos.accountKey\", COSMOS_DB_KEY) \\\n",
    "    .option(\"spark.cosmos.write.strategy\", \"ItemOverwrite\") \\\n",
    "    .save()\n",
    "\n",
    "print(\"Data written to Azure Cosmos DB\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Data-loader-no-index",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
